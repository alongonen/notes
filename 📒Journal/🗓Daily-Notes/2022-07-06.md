
## Vision Transformers
- Expressivity vs. lack of inductive bias
	- CNN are more aware to neighborhood relations
	- The Following quote from [UvA DL Notebooks](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial15/Vision_Transformer.html) seems a bit misleading:
		> In contrast, a Vision Transformer does not know which two pixels are close to each other, and which are far apart. It has to learn this information solely from the sparse learning signal of the classification task.
		
	Transformers have positional embeddings and thus have spatial knowledge.

## Dice Loss

- Defined as: $$
 1 - \frac{\sum \hat{y}_i y_i }{\sum \hat{y}_i + \sum y_i}
 $$
 where $\hat{y}_i$ is the predicted probability of the boarder in pixel $i$, and $y_i$ is the GT.


## U-Net
-  Handy Github library for using backbones in U-Net.





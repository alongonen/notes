

- Each Layer consists of the following layers:
	- `torch.nn.Linear`
	- `LayerNorm`
	- Non-linear activation layer (e.g. ReLU).


- 